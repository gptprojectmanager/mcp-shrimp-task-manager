# Eliciting Reasoning in Language Models with Cognitive Tools

**Paper ID**: arxiv:2506.12115  
**Authors**: Brown Ebouky, Andrea Bartezzaghi, Mattia Rigotti  
**Retrieved**: 2025-06-24  

## Abstract Summary
Explores alternative methods for eliciting reasoning in language models beyond chains-of-thought and reinforcement learning approaches. Research motivated by reasoning models like OpenAI's o1 and DeepSeek-R1.

## Key Results
- **GPT-4.1 Performance**: Increased pass@1 on AIME2024 from 26.7% to 43.3%
- **Near o1-preview Performance**: Achieved performance close to o1-preview using cognitive tools
- **General Improvement**: Considerable gains across mathematical reasoning benchmarks

## Theoretical Foundation
- **Cognitive Psychology**: Builds on cognitive psychology and cognitive architectures
- **Sequential Processes**: Reasoning arises from orchestrated, sequential processes
- **Alternative Methods**: Explores methods beyond chains-of-thought and RL

## Implementation Relevance
âœ… **Direct Application**: Could enhance our cognitive routing with proven reasoning elicitation  
âœ… **Performance Gains**: 62.5% improvement (26.7% â†’ 43.3%) demonstrates effectiveness  
âœ… **Sequential Processing**: Aligns with our System 1/System 2 architecture  

## Key Innovation
- **Cognitive Tools Approach**: Simple strategy with considerable performance gains
- **Post-training vs Pre-training**: Contributes to debate on reasoning mechanisms
- **Latent Abilities**: May uncover inherent capabilities from pre-training

## Status
ðŸŸ¡ **Partial Access**: Metadata and results available, need full methodology  
ðŸŽ¯ **High Priority**: Direct relevance to cognitive routing correction  
ðŸ“‹ **Action Required**: Access full implementation details

## Next Steps
1. Extract cognitive tools methodology
2. Apply reasoning elicitation to our complexity assessment
3. Integrate sequential processing patterns